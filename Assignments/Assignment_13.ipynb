{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本周只有一个代码实践题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下代码课用来加载 预先训练好的模型,你需要只需要修改模型的存放路径即可（第二行代码）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T07:22:26.714958Z",
     "start_time": "2020-01-10T07:22:22.803423Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一步 使用以下链接下载相应预训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://convaisharables.blob.core.windows.net/lsp/multiref/small_ft.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T07:22:33.707880Z",
     "start_time": "2020-01-10T07:22:26.716955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "weights = torch.load('small_ft.pkl')\n",
    "medium_config = GPT2Config(n_embd = 768,n_layer = 12, n_head = 12)\n",
    "model = GPT2LMHeadModel(medium_config)\n",
    "\n",
    "weights['lm_head.weight'] = weights['lm_head.decoder.weight']\n",
    "weights.pop('lm_head.decoder.weight',None)\n",
    "\n",
    "model.load_state_dict(weights)\n",
    "# model.train()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你需要写一个推理函数，这个函数接收一个英文句子为输入，输出一个回应。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试语句 \n",
    "一轮对话   \n",
    "1. Does money buy happiness ?   \n",
    "2. What is the best way to buy happiness?   \n",
    "\n",
    "一轮对话   \n",
    "1. what is the meaning of a godd life ?   \n",
    "2. How to be a good person ?   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T07:22:53.640195Z",
     "start_time": "2020-01-10T07:22:53.631070Z"
    }
   },
   "outputs": [],
   "source": [
    "def recalc_beam_search(n_beam = 10):\n",
    "    global conditioned_tokens\n",
    "    global generated_tokens\n",
    "    \n",
    "    indexed_tokens = generated_tokens #conditioned_tokens + generated_tokens\n",
    "\n",
    "    next_token = dict()\n",
    "    for _tokens in indexed_tokens:\n",
    "        tokens_tensor = torch.tensor([_tokens]) # \n",
    "        with torch.no_grad():\n",
    "            outputs = model(tokens_tensor)\n",
    "            predictions = outputs[0]\n",
    "\n",
    "        logits = predictions[0, -1, :]\n",
    "    \n",
    "        probabilities = F.softmax(logits, dim = -1)\n",
    "\n",
    "        sorted_probabilities, sorted_indices = torch.sort(probabilities, descending = True)\n",
    "        for i in sorted_indices[:n_beam]: #probabilities.shape[1]:\n",
    "            next_token[tuple(_tokens + [i.item()])] = probabilities[..., i,None]\n",
    "\n",
    "    next_token2 = sorted(next_token.items(), key = lambda x: x[1], reverse=True)\n",
    "    next_token2 = next_token2[:n_beam] \n",
    "\n",
    "    generated_tokens = [list(x[0]) for x in next_token2]\n",
    "    return [x[0][-1] for x in next_token2] # return end of text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T07:22:54.822056Z",
     "start_time": "2020-01-10T07:22:54.814861Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_beam_search():\n",
    "    global conditioned_tokens\n",
    "    global generated_tokens\n",
    "    \n",
    "    if len(tokenizer.decode(conditioned_tokens[0])) > 320:\n",
    "        dc = tokenizer.decode(conditioned_tokens[0])\n",
    "        dc = dc[len(dc) - 320:]\n",
    "        idx = dc.find('<|endoftext|>')\n",
    "        if idx != -1:\n",
    "            dc = dc[idx + len('<|endoftext|>'):]\n",
    "            \n",
    "        conditioned_tokens = [tokenizer.encode(dc)]\n",
    "    \n",
    "    generated_tokens = conditioned_tokens\n",
    "\n",
    "    while True:\n",
    "        result = recalc_beam_search()\n",
    "        if 50256 in result:\n",
    "            # end of text: 50256\n",
    "            \n",
    "            decoded_reply = tokenizer.decode(generated_tokens[0])\n",
    "            \n",
    "            to_print = decoded_reply\n",
    "            if to_print.endswith('<|endoftext|>'):\n",
    "                to_print = to_print[:-len('<|endoftext|>')]\n",
    "            \n",
    "            print_start = to_print.find('<|endoftext|>') + len('<|endoftext|>')\n",
    "            to_print = to_print[print_start:]\n",
    "            print(to_print)\n",
    "            \n",
    "            conditioned_tokens += [tokenizer.encode(to_print)]\n",
    "            \n",
    "            generated_tokens = [] \n",
    "            \n",
    "            break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T07:23:46.793124Z",
     "start_time": "2020-01-10T07:23:44.857670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beam search:\n",
      "\n",
      "The meaning of life\n",
      "#################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## beam search \n",
    "conditioned_tokens = []\n",
    "generated_tokens = []\n",
    "first_text = \"What is the meaning of life?\"\n",
    "conditioned_tokens += [tokenizer.encode('\\t' + first_text) + [50256]]\n",
    "print('Beam search:\\n')\n",
    "generate_beam_search()\n",
    "print('#################\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T07:24:10.105927Z",
     "start_time": "2020-01-10T07:24:08.243396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beam search:\n",
      "\n",
      "If money buys happiness\n",
      "#################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## beam search \n",
    "conditioned_tokens = []\n",
    "generated_tokens = []\n",
    "first_text = \"Does money buy happiness?\"\n",
    "conditioned_tokens += [tokenizer.encode('\\t' + first_text) + [50256]]\n",
    "print('Beam search:\\n')\n",
    "generate_beam_search()\n",
    "print('#################\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T07:24:46.163133Z",
     "start_time": "2020-01-10T07:24:44.244059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beam search:\n",
      "\n",
      "What is the meaning\n",
      "#################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## beam search \n",
    "conditioned_tokens = []\n",
    "generated_tokens = []\n",
    "first_text = \"what is the meaning of a good life?\"\n",
    "conditioned_tokens += [tokenizer.encode('\\t' + first_text) + [50256]]\n",
    "print('Beam search:\\n')\n",
    "generate_beam_search()\n",
    "print('#################\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-07T13:42:41.902086Z",
     "start_time": "2020-01-07T13:42:38.172889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-sampling:\n",
      "\n",
      "how to be a good person\n",
      "#################\n",
      "\n",
      "Beam search:\n",
      "\n",
      "what's the book?\n",
      "#################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## beam search \n",
    "conditioned_tokens = []\n",
    "generated_tokens = []\n",
    "first_text = \"How to be a good person?\"\n",
    "conditioned_tokens += [tokenizer.encode('\\t' + first_text) + [50256]]\n",
    "print('Beam search:\\n')\n",
    "generate_beam_search()\n",
    "print('#################\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
